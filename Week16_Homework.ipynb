{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.combine import SMOTEENN \n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix,classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC,LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import LocalOutlierFactor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Perform combined over and undersampling on the diabetes dataset (use SMOTEENN). Explain how combined sampling works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0              6      148             72             35        0  33.6   \n",
       "1              1       85             66             29        0  26.6   \n",
       "2              8      183             64              0        0  23.3   \n",
       "3              1       89             66             23       94  28.1   \n",
       "4              0      137             40             35      168  43.1   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "763           10      101             76             48      180  32.9   \n",
       "764            2      122             70             27        0  36.8   \n",
       "765            5      121             72             23      112  26.2   \n",
       "766            1      126             60              0        0  30.1   \n",
       "767            1       93             70             31        0  30.4   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                       0.627   50        1  \n",
       "1                       0.351   31        0  \n",
       "2                       0.672   32        1  \n",
       "3                       0.167   21        0  \n",
       "4                       2.288   33        1  \n",
       "..                        ...  ...      ...  \n",
       "763                     0.171   63        0  \n",
       "764                     0.340   27        0  \n",
       "765                     0.245   30        0  \n",
       "766                     0.349   47        1  \n",
       "767                     0.315   23        0  \n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_df = pd.read_csv(\"diabetes.csv\")\n",
    "diabetes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = diabetes_df.drop('Outcome', axis=1)\n",
    "y = diabetes_df['Outcome']\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,stratify=y,random_state=42)\n",
    "\n",
    "#Standard Scaler:\n",
    "sc= StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({1: 215, 0: 201})\n"
     ]
    }
   ],
   "source": [
    "# Applying SMOTEENN:\n",
    "sme = SMOTEENN(random_state=42)\n",
    "\n",
    "X_res, y_res = sme.fit_resample(X_train, y_train)\n",
    "print('Resampled dataset shape %s' % Counter(y_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying Logistic Regression on balanced class set:\n",
    "diabetes_log= LogisticRegression(solver='liblinear')\n",
    "diabetes_log.fit(X_train,y_train)\n",
    "\n",
    "y_pred= diabetes_log.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.42957868,  1.10919168, -0.20374881, -0.00767468, -0.07913502,\n",
       "         0.72513685,  0.23777214,  0.15312895]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_log.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.86016522])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_log.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[105,  20],\n",
       "       [ 31,  36]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_log=confusion_matrix(y_test,y_pred)\n",
    "con_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.84      0.80       125\n",
      "           1       0.64      0.54      0.59        67\n",
      "\n",
      "    accuracy                           0.73       192\n",
      "   macro avg       0.71      0.69      0.69       192\n",
      "weighted avg       0.73      0.73      0.73       192\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined Sampling:\n",
    "#### Machine learning algorithms when applied over classiciation problems often give less performance due to imbalanced datasets. Therefore, we need to balance class distribution using sampling methods.  Commonly used, sampling methods are: Oversampling, which duplicates the data from the minority class and Undersampling, which deletes the data from the majority class. While these sampling methods are applied individually on the dataset it gives good results. However, when used both methods together datasets giving better results than before. SMOTE and random sampling, SMOTEENN are most commonly used combined sampling methods. Initally SMOTE is applied over the data to create duplicates of the minority set and undersampling methods are applied to the resultant of the SMOTE to delete  the majority class.\n",
    "\n",
    "#### SMOTEENN :Initially SMOTE randomly choose data from the minority class. Then calculate distance between the random data and its knearest neighbors. Then multiply the differnce value with 0 or 1 and add the result as a new data point. This process is repeated untill desired accuracy is reached.  Next we have apply ENN to apply undersampling. Determine the value for k then find k nearest neighbors and observe the majority class in both data and k nearest. If both are different then the observation along with the nearest neighbor are deleted. Repeat this untill the desired propotion of class is reached."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Comment on the performance of combined sampling vs the other approaches we have used for the diabetes dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = diabetes_df.drop('Outcome', axis=1)\n",
    "y = diabetes_df['Outcome']\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,stratify=y,random_state=42)\n",
    "\n",
    "#Standard Scaler:\n",
    "sc= StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.fit_transform(X_test)\n",
    "\n",
    "#Standardize\n",
    "sc= StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [LogisticRegression(solver='liblinear'),SVC(), KNeighborsClassifier(),DecisionTreeClassifier(max_depth=5)]\n",
    "acc=[]\n",
    "pre=[]\n",
    "rec=[]\n",
    "\n",
    "for model in classifiers:\n",
    "    model=model.fit(X_train,y_train)\n",
    "    y_pred= model.predict(X_test)\n",
    "    #con_log=confusion_matrix(y_test,y_pred)\n",
    "    con=classification_report(y_test,y_pred,output_dict=True)\n",
    "    pre.append(con['weighted avg']['precision'])\n",
    "    rec.append(con['weighted avg']['recall'])\n",
    "    acc.append(con['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precission</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegiossion</th>\n",
       "      <td>0.734375</td>\n",
       "      <td>0.726973</td>\n",
       "      <td>0.734375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.744792</td>\n",
       "      <td>0.737991</td>\n",
       "      <td>0.744792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.710993</td>\n",
       "      <td>0.718750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecissionTree</th>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.765716</td>\n",
       "      <td>0.770833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Accuracy  Precission    Recall\n",
       "LogisticRegiossion  0.734375    0.726973  0.734375\n",
       "SVC                 0.744792    0.737991  0.744792\n",
       "KNN                 0.718750    0.710993  0.718750\n",
       "DecissionTree       0.770833    0.765716  0.770833"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Accuracy':acc,'Precission': pre, 'Recall':rec })\n",
    "df.index=('LogisticRegiossion','SVC','KNN','DecissionTree')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Outliers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(576, 8) (576,)\n",
      "(550, 8) (550,)\n"
     ]
    }
   ],
   "source": [
    "X = diabetes_df.drop('Outcome', axis=1)\n",
    "y = diabetes_df['Outcome']\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,stratify=y,random_state=42)\n",
    "\n",
    "#Standard Scaler:\n",
    "sc= StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.fit_transform(X_test)\n",
    "# Remove Outliers:\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "lof = LocalOutlierFactor()\n",
    "yhat = lof.fit_predict(X_train)\n",
    "mask = yhat != -1\n",
    "X_train, y_train = X_train[mask, :], y_train[mask]\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [LogisticRegression(solver='liblinear'),SVC(), KNeighborsClassifier(),DecisionTreeClassifier(max_depth=5)]\n",
    "acc1=[]\n",
    "pre1=[]\n",
    "rec1=[]\n",
    "\n",
    "\n",
    "for model in classifiers:\n",
    "    model=model.fit(X_train,y_train)\n",
    "    y_pred= model.predict(X_test)\n",
    "    con_log=confusion_matrix(y_test,y_pred)\n",
    "    con=classification_report(y_test,y_pred,output_dict=True)\n",
    "    pre1.append(con['weighted avg']['precision'])\n",
    "    rec1.append(con['weighted avg']['recall'])\n",
    "    acc1.append(con['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precission</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegiossion_o</th>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.721038</td>\n",
       "      <td>0.729167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC_o</th>\n",
       "      <td>0.734375</td>\n",
       "      <td>0.727897</td>\n",
       "      <td>0.734375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN_o</th>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.710993</td>\n",
       "      <td>0.718750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecissionTree_o</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.743827</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Accuracy  Precission    Recall\n",
       "LogisticRegiossion_o  0.729167    0.721038  0.729167\n",
       "SVC_o                 0.734375    0.727897  0.734375\n",
       "KNN_o                 0.718750    0.710993  0.718750\n",
       "DecissionTree_o       0.750000    0.743827  0.750000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_o=pd.DataFrame({'Accuracy':acc1,'Precission': pre1, 'Recall': rec1})\n",
    "df_o.index=('LogisticRegiossion_o','SVC_o','KNN_o','DecissionTree_o')\n",
    "df_o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying SMOTEENN to balance classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(576, 8) (576,)\n",
      "(550, 8) (550,)\n",
      "Resampled dataset shape Counter({1: 239, 0: 188})\n"
     ]
    }
   ],
   "source": [
    "X = diabetes_df.drop('Outcome', axis=1)\n",
    "y = diabetes_df['Outcome']\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,stratify=y,random_state=42)\n",
    "\n",
    "#Standard Scaler:\n",
    "sc= StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.fit_transform(X_test)\n",
    "\n",
    "# Remove Outliers:\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "\n",
    "lof = LocalOutlierFactor()\n",
    "yhat = lof.fit_predict(X_train)\n",
    "mask = yhat != -1\n",
    "\n",
    "X_train, y_train = X_train[mask, :], y_train[mask]\n",
    "print(X_train.shape, y_train.shape)\n",
    "\n",
    "sme = SMOTEENN(random_state=42)\n",
    "X_res, y_res = sme.fit_resample(X_train, y_train)\n",
    "print('Resampled dataset shape %s' % Counter(y_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers_s = [LogisticRegression(solver='liblinear'),SVC(), KNeighborsClassifier(),DecisionTreeClassifier(max_depth=5)]\n",
    "acc_s=[]\n",
    "pre_s=[]\n",
    "rec_s=[]\n",
    "\n",
    "for model in classifiers:\n",
    "    model=model.fit(X_train,y_train)\n",
    "    y_pred= model.predict(X_test)\n",
    "    con_log=confusion_matrix(y_test,y_pred)\n",
    "    con=classification_report(y_test,y_pred,output_dict=True)\n",
    "    pre_s.append(con['weighted avg']['precision'])\n",
    "    rec_s.append(con['weighted avg']['recall'])\n",
    "    acc_s.append(con['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precission</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegiossion_SMOTE</th>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.721038</td>\n",
       "      <td>0.729167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC_SMOTE</th>\n",
       "      <td>0.734375</td>\n",
       "      <td>0.727897</td>\n",
       "      <td>0.734375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN_SMOTE</th>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.710993</td>\n",
       "      <td>0.718750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecissionTree_SMOTE</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.743827</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Accuracy  Precission    Recall\n",
       "LogisticRegiossion_SMOTE  0.729167    0.721038  0.729167\n",
       "SVC_SMOTE                 0.734375    0.727897  0.734375\n",
       "KNN_SMOTE                 0.718750    0.710993  0.718750\n",
       "DecissionTree_SMOTE       0.750000    0.743827  0.750000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_smote=pd.DataFrame({'Accuracy':acc_s,'Precission': pre_s, 'Recall': rec_s})\n",
    "df_smote.index=('LogisticRegiossion_SMOTE','SVC_SMOTE','KNN_SMOTE','DecissionTree_SMOTE')\n",
    "df_smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precission</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DecissionTree</th>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.765716</td>\n",
       "      <td>0.770833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecissionTree_SMOTE</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.743827</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecissionTree_o</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.743827</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.710993</td>\n",
       "      <td>0.718750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN_SMOTE</th>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.710993</td>\n",
       "      <td>0.718750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN_o</th>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.710993</td>\n",
       "      <td>0.718750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegiossion</th>\n",
       "      <td>0.734375</td>\n",
       "      <td>0.726973</td>\n",
       "      <td>0.734375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegiossion_SMOTE</th>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.721038</td>\n",
       "      <td>0.729167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegiossion_o</th>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.721038</td>\n",
       "      <td>0.729167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.744792</td>\n",
       "      <td>0.737991</td>\n",
       "      <td>0.744792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC_SMOTE</th>\n",
       "      <td>0.734375</td>\n",
       "      <td>0.727897</td>\n",
       "      <td>0.734375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC_o</th>\n",
       "      <td>0.734375</td>\n",
       "      <td>0.727897</td>\n",
       "      <td>0.734375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Accuracy  Precission    Recall\n",
       "DecissionTree             0.770833    0.765716  0.770833\n",
       "DecissionTree_SMOTE       0.750000    0.743827  0.750000\n",
       "DecissionTree_o           0.750000    0.743827  0.750000\n",
       "KNN                       0.718750    0.710993  0.718750\n",
       "KNN_SMOTE                 0.718750    0.710993  0.718750\n",
       "KNN_o                     0.718750    0.710993  0.718750\n",
       "LogisticRegiossion        0.734375    0.726973  0.734375\n",
       "LogisticRegiossion_SMOTE  0.729167    0.721038  0.729167\n",
       "LogisticRegiossion_o      0.729167    0.721038  0.729167\n",
       "SVC                       0.744792    0.737991  0.744792\n",
       "SVC_SMOTE                 0.734375    0.727897  0.734375\n",
       "SVC_o                     0.734375    0.727897  0.734375"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sorting dataframe for better comparision:\n",
    "\n",
    "diab_model=pd.concat([df,df_smote,df_o],axis=0)\n",
    "diab_model.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "#### All the performace measures precission, accuracy,recall are very important and should be high to achieve better performance results. Therefore, in diabetes data set, a person can be falsely labeled as diabetic as he can go for further evaluaitons but a true positive canot be labeled as negative. Therefore, models with high recall need to chosen. On observations Decission Tree is considered. It also observed that removing outliers,apping smote for this set did not make any difference. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. What is outlier detection? Why is it useful? What methods can you use for outlier detection?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### “An outlier is an observation which deviates so much from the other observations as to arouse suspicions that it was generated by a different mechanism” by Hawkins.  There are various reasons outliers will happen to be in data this can be due to a machine error, measuring error, entry error or it can be intentional. Outliers can impact the model drastically and therefore needs to be addresssed. Outlier detection methods try to fit the regions that are concentrated with the data leaving the deviatant observations.  \n",
    "#### Various methods are used for outlier detection such as :\n",
    "#### 1. Standard deviation method: If the s.d of a data is greater than 3 then the point is considered as outlier.\n",
    "#### 2. Interquartile method: Points that fall below or above the interquartile range are too considered as outliers.\n",
    "#### 3. Automatic outlier detection: This can be done by importing local outlier factor from sklearn.metrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Perform a linear SVM to predict credit approval (last column) using this dataset: https://archive.ics.uci.edu/ml/datasets/Statlog+%28Australian+Credit+Approval%29 . Make sure you look at the accompanying document that describes the data in the dat file. You will need to either convert this data to another file type or import the dat file to python. \n",
    "You can use this code, but otherwise you follow standard practices we have already used many times: \n",
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel='linear')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>A11</th>\n",
       "      <th>A12</th>\n",
       "      <th>A13</th>\n",
       "      <th>A14</th>\n",
       "      <th>A15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>29.58</td>\n",
       "      <td>1.750</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>280</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>21.67</td>\n",
       "      <td>11.500</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>20.17</td>\n",
       "      <td>8.170</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1.960</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>159</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>15.83</td>\n",
       "      <td>0.585</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1.500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>17.42</td>\n",
       "      <td>6.500</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>1</td>\n",
       "      <td>43.00</td>\n",
       "      <td>0.290</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>1.750</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>376</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>1</td>\n",
       "      <td>31.57</td>\n",
       "      <td>10.500</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>6.500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>1</td>\n",
       "      <td>20.67</td>\n",
       "      <td>0.415</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>0</td>\n",
       "      <td>18.83</td>\n",
       "      <td>9.540</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.085</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>0</td>\n",
       "      <td>27.42</td>\n",
       "      <td>14.500</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>3.085</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>120</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>687 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     A1     A2      A3  A4  A5  A6     A7  A8  A9  A10  A11  A12  A13  A14  \\\n",
       "0     0  29.58   1.750   1   4   4  1.250   0   0    0    1    2  280    1   \n",
       "1     0  21.67  11.500   1   5   3  0.000   1   1   11    1    2    0    1   \n",
       "2     1  20.17   8.170   2   6   4  1.960   1   1   14    0    2   60  159   \n",
       "3     0  15.83   0.585   2   8   8  1.500   1   1    2    0    2  100    1   \n",
       "4     1  17.42   6.500   2   3   4  0.125   0   0    0    0    2   60  101   \n",
       "..   ..    ...     ...  ..  ..  ..    ...  ..  ..  ...  ...  ...  ...  ...   \n",
       "682   1  43.00   0.290   1  13   8  1.750   1   1    8    0    2  100  376   \n",
       "683   1  31.57  10.500   2  14   4  6.500   1   0    0    0    2    0    1   \n",
       "684   1  20.67   0.415   2   8   4  0.125   0   0    0    0    2    0   45   \n",
       "685   0  18.83   9.540   2   6   4  0.085   1   0    0    0    2  100    1   \n",
       "686   0  27.42  14.500   2  14   8  3.085   1   1    1    0    2  120   12   \n",
       "\n",
       "     A15  \n",
       "0      0  \n",
       "1      1  \n",
       "2      1  \n",
       "3      1  \n",
       "4      0  \n",
       "..   ...  \n",
       "682    1  \n",
       "683    1  \n",
       "684    0  \n",
       "685    1  \n",
       "686    1  \n",
       "\n",
       "[687 rows x 15 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.genfromtxt('australian.dat',\n",
    "                     skip_header=1,\n",
    "                     skip_footer=1,\n",
    "                     names=True,\n",
    "                     dtype=None,\n",
    "                     delimiter=' ')\n",
    "df_c=pd.DataFrame(data)\n",
    "df_c.columns=['A1','A2','A3','A4','A5','A6','A7','A8','A9','A10','A11','A12','A13','A14','A15']\n",
    "df_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>A11</th>\n",
       "      <th>A12</th>\n",
       "      <th>A13</th>\n",
       "      <th>A14</th>\n",
       "      <th>A15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>687.000000</td>\n",
       "      <td>687.000000</td>\n",
       "      <td>687.000000</td>\n",
       "      <td>687.000000</td>\n",
       "      <td>687.000000</td>\n",
       "      <td>687.000000</td>\n",
       "      <td>687.000000</td>\n",
       "      <td>687.000000</td>\n",
       "      <td>687.000000</td>\n",
       "      <td>687.000000</td>\n",
       "      <td>687.000000</td>\n",
       "      <td>687.000000</td>\n",
       "      <td>687.000000</td>\n",
       "      <td>687.000000</td>\n",
       "      <td>687.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.678311</td>\n",
       "      <td>31.581237</td>\n",
       "      <td>4.752576</td>\n",
       "      <td>1.765648</td>\n",
       "      <td>7.372635</td>\n",
       "      <td>4.695779</td>\n",
       "      <td>2.230509</td>\n",
       "      <td>0.525473</td>\n",
       "      <td>0.427948</td>\n",
       "      <td>2.409025</td>\n",
       "      <td>0.458515</td>\n",
       "      <td>1.930131</td>\n",
       "      <td>183.624454</td>\n",
       "      <td>1021.064047</td>\n",
       "      <td>0.445415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.467465</td>\n",
       "      <td>11.863305</td>\n",
       "      <td>4.978474</td>\n",
       "      <td>0.430725</td>\n",
       "      <td>3.687621</td>\n",
       "      <td>1.996140</td>\n",
       "      <td>3.351769</td>\n",
       "      <td>0.499715</td>\n",
       "      <td>0.495142</td>\n",
       "      <td>4.871537</td>\n",
       "      <td>0.498639</td>\n",
       "      <td>0.297331</td>\n",
       "      <td>171.904268</td>\n",
       "      <td>5221.187569</td>\n",
       "      <td>0.497374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.670000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.165000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>28.670000</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>37.665000</td>\n",
       "      <td>7.165000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.667500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>272.000000</td>\n",
       "      <td>396.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>80.250000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>28.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>100001.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               A1          A2          A3          A4          A5          A6  \\\n",
       "count  687.000000  687.000000  687.000000  687.000000  687.000000  687.000000   \n",
       "mean     0.678311   31.581237    4.752576    1.765648    7.372635    4.695779   \n",
       "std      0.467465   11.863305    4.978474    0.430725    3.687621    1.996140   \n",
       "min      0.000000   13.750000    0.000000    1.000000    1.000000    1.000000   \n",
       "25%      0.000000   22.670000    1.000000    2.000000    4.000000    4.000000   \n",
       "50%      1.000000   28.670000    2.750000    2.000000    8.000000    4.000000   \n",
       "75%      1.000000   37.665000    7.165000    2.000000   10.000000    5.000000   \n",
       "max      1.000000   80.250000   28.000000    3.000000   14.000000    9.000000   \n",
       "\n",
       "               A7          A8          A9         A10         A11         A12  \\\n",
       "count  687.000000  687.000000  687.000000  687.000000  687.000000  687.000000   \n",
       "mean     2.230509    0.525473    0.427948    2.409025    0.458515    1.930131   \n",
       "std      3.351769    0.499715    0.495142    4.871537    0.498639    0.297331   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    1.000000   \n",
       "25%      0.165000    0.000000    0.000000    0.000000    0.000000    2.000000   \n",
       "50%      1.000000    1.000000    0.000000    0.000000    0.000000    2.000000   \n",
       "75%      2.667500    1.000000    1.000000    3.000000    1.000000    2.000000   \n",
       "max     28.500000    1.000000    1.000000   67.000000    1.000000    3.000000   \n",
       "\n",
       "               A13            A14         A15  \n",
       "count   687.000000     687.000000  687.000000  \n",
       "mean    183.624454    1021.064047    0.445415  \n",
       "std     171.904268    5221.187569    0.497374  \n",
       "min       0.000000       1.000000    0.000000  \n",
       "25%      80.000000       1.000000    0.000000  \n",
       "50%     160.000000       6.000000    0.000000  \n",
       "75%     272.000000     396.000000    1.000000  \n",
       "max    2000.000000  100001.000000    1.000000  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_c.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_c.drop('A15', axis=1)\n",
    "y = df_c['A15']\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,stratify=y,random_state=24)\n",
    "\n",
    "#Standard Scaler:\n",
    "sc= StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[72 23]\n",
      " [ 8 69]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import confusion_matrix, classification_report, plot_confusion_matrix\n",
    "\n",
    "model = SVC(kernel='linear')\n",
    "\n",
    "model = model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.76      0.82        95\n",
      "           1       0.75      0.90      0.82        77\n",
      "\n",
      "    accuracy                           0.82       172\n",
      "   macro avg       0.82      0.83      0.82       172\n",
      "weighted avg       0.83      0.82      0.82       172\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Score: 0.8197674418604651\n",
      "Training Score: 0.8699029126213592\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing Score:\",model.score(X_test,y_test))\n",
    "print(\"Training Score:\",model.score(X_train,y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. How did the SVM model perform? Use a classification report. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8197674418604651\n",
      "Precision : 0.75\n",
      "Sensitivity/Recall: 0.8961038961038961\n",
      "Specificity: 0.7578947368421053\n"
     ]
    }
   ],
   "source": [
    "TN = cm[0,0]\n",
    "TP = cm[1,1]\n",
    "FN = cm[1,0]\n",
    "FP = cm[0,1]\n",
    "\n",
    "Accuracy_logl= (TN + TP) / (TN+ TP + FN + FP)\n",
    "print(\"Accuracy:\",Accuracy_logl)\n",
    "\n",
    "precision = TP / (TP + FP)\n",
    "print(\"Precision :\", precision)\n",
    "\n",
    "sensitivity = TP / (FN + TP)\n",
    "print(\"Sensitivity/Recall:\", sensitivity)\n",
    "\n",
    "specificity = TN / (TN + FP)\n",
    "print(\"Specificity:\", specificity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using classification report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names=['Not_Approved','Appoved']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "Not_Approved       0.90      0.76      0.82        95\n",
      "     Appoved       0.75      0.90      0.82        77\n",
      "\n",
      "    accuracy                           0.82       172\n",
      "   macro avg       0.82      0.83      0.82       172\n",
      "weighted avg       0.83      0.82      0.82       172\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred,target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model has good performance results as to sensitivity /recall value is almost 95% which means approving a credit to the correct individual is happening 95% of times. Which inturn tells that correct factors are considered while checking for loan approval.  Also, accuracy, precission and specificity values are pretty good. F1 score which is harmonic mean of precission and recall is also good indicator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. What kinds of jobs in data are you most interested in? Do some research on what is out there. Write about your thoughts in under 400 words. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data science career involves in collecting,shaping,storing,managing and analyzing information from the data. Data science can be applied in various fields such as recommendations for the movies, purchases, credit fraud, medicine for analysis of disease, manufacturing to predict machine break downs and many more. With my thetorical educational background of engineering i always loved and worked with data to draw some conclusions, making process better. Now, after exposure to data science my urge to work with data has been increased. After researching on the career scope with data science fields most attracted role include data scientist working with large complex data cleaning to drive strategic business decisisions, machine learning positions that involves in applying different machine learning algorithms and would also like to work on interactive visualizations softwares to present my predicitons to the business."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
